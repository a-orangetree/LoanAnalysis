---
title: "Lending on Prosper using only Loan Characteristics"
author: "Adrian Naranjo"
---

<br>

```{r, message=FALSE, echo=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(gridExtra)
library(knitr)
library(kableExtra)
library(ggthemes)

library(class)
library(modelr)
library(car)
library(xgboost)
library(randomForest)
library(glmnet)

theme_set(theme_fivethirtyeight())

set.seed(10)

df_2013 <- read_csv('data/Loans_20130101to20140101_20180415T060158.csv') %>% mutate(year = 2013)
df_2014 <- read_csv('data/Loans_20140101to20150101_20180415T060226.csv') %>% mutate(year = 2014)
df_2015 <- read_csv('data/Loans_20150101to20160101_20180415T060359.csv') %>% mutate(year = 2015)
df_2017 <- read_csv('data/Loans_20170101to20180101_20180415T060911.csv') %>% mutate(year = 2017)
df_2018 <- read_csv('data/Loans_20180101toCurrent_20180415T061114.csv') %>% mutate(year = 2018)


df_2018 <- df_2018 %>% mutate(loan_default_reason = as.integer(loan_default_reason))


df_all_years <- bind_rows(df_2013, df_2014, df_2015, df_2017, df_2018)
df_all_years_raw <- df_all_years


df_all_years <- df_all_years %>% 
  mutate(lost_money = factor(ifelse(loan_status_description == 'COMPLETED' & next_payment_due_amount == 0, 0, 1)
                             , levels = c(0, 1))
         ,late_fees_flag = factor(ifelse(late_fees_paid == 0, 0, 1))
         ,has_next_payment_flag = factor(ifelse(next_payment_due_amount == 0, 0, 1), levels = c(0, 1))
         ,prosper_rating = factor(prosper_rating, levels = c('AA', 'A', 'B', 'C', 'D', 'E', 'HR'))
         ,term = factor(term)
         ,year = factor(year)
         ,loan_status_description = factor(loan_status_description)
         ,service_fees_paid = service_fees_paid * -1
         ,total_paid = principal_paid + service_fees_paid + interest_paid + prosper_fees_paid + late_fees_paid
         ,total_fees_paid = service_fees_paid + interest_paid + prosper_fees_paid + late_fees_paid
         ,month_of_origination = month(origination_date))

df_all_years <- df_all_years %>%
  select(-loan_default_reason, -loan_default_reason_description, -loan_status, -loan_status_description
         ,-loan_number, -year, -origination_date, -days_past_due, -late_fees_paid, -debt_sale_proceeds_received
         ,-late_fees_flag, -has_next_payment_flag, -next_payment_due_amount, -next_payment_due_date)

df_all_years <- drop_na(df_all_years)

training_data <- sample_frac(df_all_years, .75)
testing_data <- anti_join(df_all_years, training_data)

mod <- read_csv('data_lessVariables/model_accuracies.csv')
```


#### **The Question**: Can we predict Microlending Loan Defaults (on a website called Prosper)?

<br>

#### What you should know before reading:

* Our observations consisted of approximately 677K loans from the years 2013, 2014, 2015, 2016, 2017, and 2018. For more information about the data, please view the preliminary descriptive analysis entitled EDA.html in this folder.

<br>

* The original raw data contained over 20 variables. What was not realized until the modeling process began was that only several of these variables are actually known prior to deciding to lend money on Prosper. Thus, the variables used within the models has been significantly trimmed (columns are displayed below).

<br>

* It was also expected that data about borrowers would be available. While the data was acquired, a means to linking that data to the loan data used has not been found (i.e. there's no common identifier between the datasets).

<br>

* All models were trained and tested on Northwestern's Quest computing cluster due to the size of the dataset.

<br>

#### Columns used:

```{r, message=FALSE, echo=FALSE, warning=FALSE}
c("Amount Borrowed","Borrower Rating","Term of Loan","Interest Rate") %>% 
  kable(col.names = c('Logistic Regression Variables'), format = 'html') %>% 
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

<br>

### Model 1: Logistic Regression

All the predictors returned as significant, however there was multicollinearity between "Borrower Rating" and "Interest Rate" (variance inflation factor was at 4).

```{r, message=FALSE, echo=FALSE, warning=FALSE}
############ Logistic Regression #####################
linear_accuracy <- round(drop_na(select(mod, contains('linear'))), 3)

linear_accuracy %>% 
  kable(align = c('c'), col.names = c('Logistic Regression Accuracy'), format = 'html') %>% 
  kable_styling(full_width = F, position = "left")
```

<br>

### Model 2: Ridge Regression

Ridge Regression and Lasso models were fit using cross-validation to attain the best lambda.

```{r, message=FALSE, echo=FALSE, warning=FALSE}
###### Ridge Regression ############
ridge_reg_accuracy <- round(drop_na(select(mod, contains('ridge'))),3)

ridge_reg_accuracy %>% 
  kable(align = c('c'), col.names = c('Ridge Regression Accuracy'), format = 'html') %>% 
  kable_styling(full_width = F, position = "left")
```

<br>

### Model 3: Lasso

Lasso perfored effectively the same as Ridge Regression. Given the small amount of variables, this is not necessarily surprising.

```{r, message=FALSE, echo=FALSE, warning=FALSE}
########### Lasso ##################
lasso_accuracy <- round(drop_na(select(mod, contains('lasso'))), 3)

lasso_accuracy %>% 
  kable(align = c('c'), col.names = c('Lasso Accuracy'), format = 'html') %>% 
  kable_styling(full_width = F, position = "left")
```

<br>

### Model 4: K-Nearest Neighbor

To find the optimal k, a grid search was performed with the result displayed below.

K-values tested: **1, 3, 5, 10, 25, 50, 75, 100**

```{r, message=FALSE, echo=FALSE, warning=FALSE}
##### Plot for KNN Grid Search ##############
knn_accuracies <- read_csv('data_lessVariables/knn_accuracies.csv') %>% 
  filter(!accuracy == 0) %>% 
  arrange(desc(accuracy))

knn_accuracy <- knn_accuracies$accuracy[1]

ggplot(knn_accuracies, aes(x = k, y = accuracy)) +
  geom_point(size = 4) +
  ggtitle('Grid Search for Best k') +
  labs(x = 'K', y = 'Accuracy')
```

<br>

### Model 5: Boosted Tree

To obtain these parameters a grid search was performed using Quest (the parameters and ranges for each can be found below). Furthermore, 10-fold cross-validation was used with an early stopping parameter of 10. 

* Number of rounds: **100, 500, 1000, 2500, 5000, 10000**
* Learning rate: **.001, .003, .005, .01, .03, .05, .1**
* Gamma: **1, 5, 20, 50, 100**
* Max depth: **2, 4, 6, 10, 20**

Below are the top combinations which appeared and their respective accuracies:

```{r, message=FALSE, echo=FALSE, warning=FALSE}
######### Graph for Best XgBoost Parameters ############
xgboost_accuracies <- read_csv('data_lessVariables/boost_accuracies.csv') %>% 
  filter(!error == 0) %>% 
  mutate(accuracy = round(1.0 - error, 3)) %>% 
  select(-error, -number_of_rounds, -best_ntreelimit) %>%
  rename('number_of_rounds' = 'best_iteration') %>% 
  arrange(desc(accuracy)) %>% 
  head(5) 

boosted_accuracy <- xgboost_accuracies$accuracy[1]

kable(xgboost_accuracies, format = 'html') %>% 
  kable_styling(full_width = F, position = "left")
```

<br>

### Model 6: Random Forest

Similar to boosted tree models, random forest models were fit and the parameters used to achieve the best accuracy were found through a grid search. Out-of-bag accuracy was used instead of out-of-sample. 

* Number of trees: **100, 500, 1000, 2000, 4000, 5000, 7500, 10000**
* Number of variables considered at each step: **1, 2, 3, 4**
* Minimum observations in each node: **1, 10, 25, 50, 100, 150**
* Number of terminal nodes:  **100, 500, 1000, 2500**

Below are the top combinations which appeared and their respective accuracies:

```{r, message=FALSE, echo=FALSE, warning=FALSE}
######### Graph for Best Random Forest Parameters ############
rf_accuracies <- read_csv('data_lessVariables/rf_grid_search1.csv') %>% 
  filter(!accuracy == 0) %>% 
  mutate(accuracy = round(accuracy, 3)) %>% 
  arrange(desc(accuracy)) %>% 
  head(5) 

rf_accuracy <- rf_accuracies$accuracy[1]

kable(rf_accuracies, format = 'html') %>% 
  kable_styling(full_width = F, position = "left")
```

<br>

### Accuracy Recap

None of the models performed well enough to be used as the sole criteria in making a decision as whether to lend money. Only an above 90% could prove convincing. Given the size of the number of observations and, though unexpected, small amount of variables, it was difficult prior to modeling which classification model would perform best. 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
accuracies <- tibble(model = c('Logistic Regression', 'Ridge Regression', 'Lasso', 'KNN', 'Boosted Trees', 'Random Forest')
                     ,accuracy = as.double(c(linear_accuracy, ridge_reg_accuracy, lasso_accuracy
                                             ,knn_accuracy, boosted_accuracy, rf_accuracy))) 

accuracies <- accuracies %>% arrange(desc(accuracy)) %>% mutate(accuracy = round(accuracy, 3))

kable(accuracies, align = c(rep('c', 6)), format = 'html') %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, position = "left") 
```

<br>

### Future Work

* The number one priority should be to link more variables with the current data. Data about borrowers is available, however I have yet to find a way to combine it with loan data.

* An SVM and neural networks can be attempted with or without more data. A neural network has not been yet due to issues with the Keras/TensorFlow libraries and Northwestern's Quest computing clusters.

* Cross-validation can be incorporated into Logistic Regression.